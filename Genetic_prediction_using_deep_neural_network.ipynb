{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Genetic prediction using deep neural network",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexkychen/FASTQ_tools/blob/master/Genetic_prediction_using_deep_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saWIu3yQlhwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFR8X2SN6kFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use a callback to cancel training process if accuracy is over a certain percentage\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.6):\n",
        "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9UhRtB7sN6r",
        "colab_type": "code",
        "outputId": "c4ce9dc8-b5bc-48e1-b942-89e810cc9602",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "myfile = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4f0d559e-6b5b-44eb-8a50-eff1cb0b45f0\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-4f0d559e-6b5b-44eb-8a50-eff1cb0b45f0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving simGenepop.txt to simGenepop.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWHEUvwzAXRp",
        "colab_type": "code",
        "outputId": "350e6ada-a6da-4e78-e2a0-40c75ff54240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "#myfile is a dictionary with filename as key and file content as values\n",
        "\n",
        "for i in myfile.keys():\n",
        "  content = myfile.get(i).decode(\"utf-8\")\n",
        "\n",
        "#separate content into list by line \n",
        "content = content.splitlines()\n",
        "#get first line\n",
        "first_line = content[0]\n",
        "print(\"Imported file description: \" + str(first_line))\n",
        "\n",
        "#check if third item is \"pop\" and get locus name \n",
        "if content[2].strip().lower() == \"pop\": #for format A\n",
        "  loci = content[1].strip()\n",
        "  #split locus name by comma\n",
        "  loci = loci.split(\",\")\n",
        "  loci = [i.strip() for i in loci]\n",
        "  \n",
        "else: #for format B\n",
        "  #searching first \"pop\"\n",
        "  i = 0\n",
        "  for p in content:\n",
        "    i = i + 1\n",
        "    if p.strip().lower() == \"pop\":\n",
        "      break\n",
        "  #get locus name\n",
        "  loci = content[1:i-1]\n",
        "\n",
        "print(\"Number of loci: \" + str(len(loci)))\n",
        "\n",
        "#get population and sample size\n",
        "noPop = 0\n",
        "ind = 0\n",
        "popSize = tuple()\n",
        "\n",
        "for p in content:\n",
        "  ind = ind + 1\n",
        "  if p.strip().lower() == \"pop\":\n",
        "    if noPop > 0:\n",
        "      popSize = popSize + (ind-1,)\n",
        "    noPop = noPop + 1\n",
        "    ind = 0\n",
        "#add last pop size to popSize\n",
        "popSize = popSize + (ind,)\n",
        "\n",
        "print(\"Number of populations: \"+ str(noPop))\n",
        "print(\"Population sizes are: \"+str(popSize))\n",
        "print(\"Total sample size: \" +str(sum(popSize)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imported file description: Title line:\"A series of simulated samples\"\n",
            "Number of loci: 1000\n",
            "Number of populations: 3\n",
            "Population sizes are: (30, 30, 30)\n",
            "Total sample size: 90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu3rvN2K2KWa",
        "colab_type": "code",
        "outputId": "70ce636f-9c94-47d6-f4f5-6534b919620f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#get sample ID and genetic data\n",
        "sampleID = []\n",
        "sampleLoc = []\n",
        "indata = False\n",
        "\n",
        "#go through each line\n",
        "for p in content:\n",
        "  if p.strip().lower() == \"pop\":\n",
        "    indata = True\n",
        "    continue\n",
        "  #acquire sample ID and loci from each individual\n",
        "  if indata:\n",
        "    onerow = [i.strip() for i in p.split(',')]\n",
        "    id = onerow[0]\n",
        "    loc = onerow[1]\n",
        "    sampleID.append(id)\n",
        "    sampleLoc.append(loc)\n",
        "\n",
        "#turn sampleLoc to a numpy array     \n",
        "sampleLoc = np.asarray([tuple(i.split()) for i in sampleLoc])\n",
        "print(\"array size:\" + str(sampleLoc.shape))\n",
        "#print(sampleLoc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "array size:(90, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ3p2Euf28t4",
        "colab_type": "code",
        "outputId": "54e364ce-4aed-4b69-b70e-6478082454f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#get split size from a locus\n",
        "splitSize = int(len(sampleLoc[0][0])/2)\n",
        "\n",
        "#split each locus\n",
        "locSplit = np.split(sampleLoc, len(loci), axis=1)\n",
        "\n",
        "#split alleles\n",
        "sampleAle = np.array(locSplit).view((str,splitSize))\n",
        "print(\"(loci, individuals, ploidy) = \" + str(sampleAle.shape))\n",
        "\n",
        "#empty array for genetic data\n",
        "geneArray = np.array([]).reshape(len(sampleID),0) \n",
        "\n",
        "#get unique allele of each locus\n",
        "for i in range(len(loci)):\n",
        "  alleles = np.unique(sampleAle[i])\n",
        "  #print(alleles)\n",
        "  #one hot encode alleles\n",
        "  #for diploid\n",
        "  firstAleIndex = np.array([np.where(alleles==j)[0][0] for j in sampleAle[i][:,0]])\n",
        "  init = np.zeros((len(sampleID), len(alleles)))\n",
        "  init[np.arange(len(sampleID)), firstAleIndex] = 0.5\n",
        "  \n",
        "  secndAleIndex = np.array([np.where(alleles==k)[0][0] for k in sampleAle[i][:,1]])\n",
        "  init2 = np.zeros((len(sampleID), len(alleles)))\n",
        "  init2[np.arange(len(sampleID)), secndAleIndex] = 0.5\n",
        "  \n",
        "  #half_one_hot encode for a locus\n",
        "  init = init + init2\n",
        "  \n",
        "  #remove missing value (\"00\" or \"000\") columns\n",
        "  if int(alleles[0]) == 0:\n",
        "    init = init[:,1:]\n",
        "  \n",
        "  #concatenate arrays \n",
        "  if init.shape[1] != 0:\n",
        "    geneArray = np.concatenate((geneArray, init), axis=1)\n",
        "  #for haploid \n",
        "  # (reserved) \n",
        "  \n",
        "print(\"Shape of genetic data (individuals, alleles) = \" + str(geneArray.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(loci, individuals, ploidy) = (1000, 90, 2)\n",
            "Shape of genetic data (individuals, alleles) = (90, 2000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc6Z85G0FVoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create label array\n",
        "popArray = np.zeros((len(sampleID), noPop))\n",
        "#for loop each pop\n",
        "start = 0\n",
        "for p in range(noPop):\n",
        "  end = start + popSize[p]\n",
        "  popArray[start:end, p] = 1\n",
        "  start = end\n",
        "\n",
        "#popArray"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRKwcBW_F27G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#shuffle individuals\n",
        "s = np.arange(len(sampleID))\n",
        "np.random.shuffle(s)\n",
        "\n",
        "geneArrayS = geneArray[s]\n",
        "popArrayS = popArray[s]\n",
        "\n",
        "trainProp = 0.7\n",
        "lastTrainInd = int(len(sampleID)*trainProp)\n",
        "train_data, test_data = geneArrayS[0:lastTrainInd+1], geneArrayS[lastTrainInd+1:]\n",
        "train_label, test_label = popArrayS[0:lastTrainInd+1], popArrayS[lastTrainInd+1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fB_S0iNqaR3",
        "colab_type": "code",
        "outputId": "aab3bde5-8ac4-4816-af49-1dc699fb6526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "#define model\n",
        "model = tf.keras.Sequential([tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                             tf.keras.layers.Dropout(0.3),\n",
        "                             tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                             tf.keras.layers.Dropout(0.3),\n",
        "                             tf.keras.layers.Dense(3, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data, train_label, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 0s 4ms/sample - loss: 12.7461 - acc: 0.3175\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 0s 1ms/sample - loss: 14.0784 - acc: 0.3333\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 0s 1ms/sample - loss: 1.2928 - acc: 0.4286\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 0s 1ms/sample - loss: 0.9568 - acc: 0.5714\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 0s 1ms/sample - loss: 1.0814 - acc: 0.5238\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 0s 1ms/sample - loss: 0.8522 - acc: 0.5397\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 0s 1ms/sample - loss: 1.3105 - acc: 0.4286\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 0s 1ms/sample - loss: 0.7621 - acc: 0.5714\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 0s 1ms/sample - loss: 1.0821 - acc: 0.5714\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 0s 1ms/sample - loss: 0.6462 - acc: 0.6984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iWAbW4Y6k1P",
        "colab_type": "code",
        "outputId": "15ff5569-aa41-4750-ee9f-9ee41ab387d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#evaluate on test data\n",
        "results = model.evaluate(test_data, test_label)\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r27/27 [==============================] - 0s 5ms/sample - loss: 0.9981 - acc: 0.4815\n",
            "[0.9981279969215393, 0.4814815]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqqQfAEt70H0",
        "colab_type": "code",
        "outputId": "14080a73-1c0d-4d79-9199-7c23be36a470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNnNLOUBlrev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_x = np.random.random(size=(30, 100)) #30 indiviauls and 100 loci\n",
        "input_y = np.random.randint(2, size=(30,1)) #one label (pop) for 30 individuals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr-4dCu_aQLS",
        "colab_type": "code",
        "outputId": "042a1b8f-f8ad-43b6-a34f-3b22e7dadfe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "pop_A = np.random.randint(1,10, size=(30,100)) /24\n",
        "pop_B = np.random.randint(8,17, size=(30,100)) / 24\n",
        "pop_C = np.random.randint(15,24, size=(30,100)) / 24\n",
        "\n",
        "array_0 = np.zeros((30,1))\n",
        "array_1 = np.ones((30,1))\n",
        "\n",
        "pop_A_label = np.concatenate((array_1, array_0, array_0), axis=1)\n",
        "pop_B_label = np.concatenate((array_0, array_1, array_0), axis=1)\n",
        "pop_C_label = np.concatenate((array_0, array_0, array_1), axis=1)\n",
        "\n",
        "train_data = np.concatenate((pop_A,pop_B,pop_C), axis=0) #shape = (90, 100) 90 individuals and 100 loci\n",
        "train_label = np.concatenate((pop_A_label,pop_B_label,pop_C_label), axis=0)\n",
        "\n",
        "print(\"train data shape: \" + str(train_data.shape))\n",
        "print(\"train label shape: \"+ str(train_label.shape))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data shape: (90, 100)\n",
            "train label shape: (90, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-WROwrghWMZ",
        "colab_type": "code",
        "outputId": "99fecb6f-fde6-4615-c0ba-cf6056531742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "train_data[0:4, 0:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.125     , 0.125     , 0.33333333, 0.04166667, 0.375     ,\n",
              "        0.33333333, 0.20833333, 0.04166667, 0.04166667, 0.29166667],\n",
              "       [0.08333333, 0.16666667, 0.29166667, 0.125     , 0.20833333,\n",
              "        0.125     , 0.16666667, 0.125     , 0.04166667, 0.04166667],\n",
              "       [0.25      , 0.375     , 0.375     , 0.375     , 0.08333333,\n",
              "        0.29166667, 0.33333333, 0.29166667, 0.25      , 0.375     ],\n",
              "       [0.08333333, 0.375     , 0.29166667, 0.125     , 0.33333333,\n",
              "        0.08333333, 0.33333333, 0.375     , 0.25      , 0.25      ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgUZuF7teU1h",
        "colab_type": "code",
        "outputId": "f36ce8f0-065a-4b47-e52a-0b1353c96937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#shuffle the data\n",
        "s = np.arange(train_data.shape[0])\n",
        "np.random.shuffle(s)\n",
        "s"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3, 73,  7, 43, 18, 35, 86, 42, 40,  9, 71, 64, 74, 75, 37, 31, 72,\n",
              "       47, 10, 30,  4, 20, 77, 26, 53, 79,  1, 22, 60, 16, 33, 38, 21, 65,\n",
              "       87, 81, 13, 63, 80, 29, 52, 34, 56, 41, 57, 27, 61, 55, 50, 66,  6,\n",
              "       12, 23, 83, 67, 69, 28, 85, 15, 82, 89, 49,  0, 39, 76, 11, 58, 68,\n",
              "       88, 25, 54, 46, 36, 45, 44, 24, 59, 19, 62, 48,  2, 84,  5, 32, 78,\n",
              "        8, 17, 51, 14, 70])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB2D7uIHhyeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_data[s]\n",
        "train_label = train_label[s]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whMZSjQJnH3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define model\n",
        "model = tf.keras.Sequential([tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                             #tf.keras.layers.Dropout(0.3),\n",
        "                             tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                             #tf.keras.layers.Dropout(0.3),\n",
        "                             tf.keras.layers.Dense(3, activation=tf.nn.softmax)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp2hoaA-qW9H",
        "colab_type": "code",
        "outputId": "c552c703-8f59-4685-af7d-7c1558a8b1db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#model.fit(input_x, input_y, epochs=10, callbacks=[callbacks])\n",
        "history = model.fit(train_data, train_label, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "90/90 [==============================] - 0s 977us/sample - loss: 1.2075 - acc: 0.6556\n",
            "Epoch 2/10\n",
            "90/90 [==============================] - 0s 109us/sample - loss: 0.4588 - acc: 0.9667\n",
            "Epoch 3/10\n",
            "90/90 [==============================] - 0s 107us/sample - loss: 0.4319 - acc: 0.8333\n",
            "Epoch 4/10\n",
            "90/90 [==============================] - 0s 99us/sample - loss: 0.3991 - acc: 0.8889\n",
            "Epoch 5/10\n",
            "90/90 [==============================] - 0s 101us/sample - loss: 0.4067 - acc: 0.8333\n",
            "Epoch 6/10\n",
            "90/90 [==============================] - 0s 109us/sample - loss: 0.3457 - acc: 0.9444\n",
            "Epoch 7/10\n",
            "90/90 [==============================] - 0s 86us/sample - loss: 0.3532 - acc: 0.9333\n",
            "Epoch 8/10\n",
            "90/90 [==============================] - 0s 110us/sample - loss: 0.3276 - acc: 0.9778\n",
            "Epoch 9/10\n",
            "90/90 [==============================] - 0s 122us/sample - loss: 0.4729 - acc: 0.6778\n",
            "Epoch 10/10\n",
            "90/90 [==============================] - 0s 97us/sample - loss: 0.3416 - acc: 0.8889\n",
            "{'loss': [1.2074890481101141, 0.4587904042667813, 0.4318959845436944, 0.39906333949830797, 0.4066532042291429, 0.3457029660542806, 0.3531878544224633, 0.3276328510708279, 0.4729237894217173, 0.3415631267759535], 'acc': [0.65555555, 0.96666664, 0.8333333, 0.8888889, 0.8333333, 0.9444444, 0.93333334, 0.9777778, 0.67777777, 0.8888889]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGzzvXY_nECz",
        "colab_type": "code",
        "outputId": "b8cc4dad-2eaf-4043-9fd0-b232ac24fb82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_data = np.random.randint(1,10, size=(5,100)) /24\n",
        "\n",
        "array_0_test = np.zeros((5,1))\n",
        "array_1_test = np.ones((5,1))\n",
        "\n",
        "test_label = np.concatenate((array_1_test, array_0_test, array_0_test), axis=1)\n",
        "results = model.evaluate(test_data, test_label)\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r5/5 [==============================] - 0s 299us/sample - loss: 0.1838 - acc: 1.0000\n",
            "[0.18382574617862701, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTtNzxweqB5v",
        "colab_type": "code",
        "outputId": "1c44467a-c55d-4562-d566-286528b9c6ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                multiple                  6464      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  4160      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  195       \n",
            "=================================================================\n",
            "Total params: 10,819\n",
            "Trainable params: 10,819\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd1C_qXE7J78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}